- query, q = 방탄소년단 -> iu등으로 바꿀수 있음 

- 크롬(브라우저) 가 html 파일의 모습들을 표현해주는것 

- 클라이언트 = 나 // 서버 = 네이버 

- request : 요청과 응답을 처리해주는 python library 

- response (200) = 성공적으로 정보를 가져왔다는 약속 

- 검사 -> copy -> copy selector (선택자라는 것을 통해 자기가 원하는 부분만 가져올 수 있다)

-  select 쓰기(beautiful soup에서)

- json 은 beautifulsoup 안써도된다 

- api에 보내는 요청건수는 하루에 정해진 횟수가 있다. 

- 파일데이터: 과거데이터 

- 실시간 받고싶으면 오픈API 활용 

- beautifulsoup은 html소스코드를 태그 기준으로 파싱하기위해 사용!

  ## 어떻게 요청할건지 응답결과를 어떻게 활용할건지 

- api_key ~~ : params 

- get  /movie.noew_playing 

- 4: 요청을 잘못보냄 5: 서버에서 잘못 2: 잘됨 

- /movie/now_playing 이런 주소가 path에 해당하는 것 

- Query String 을 보고 dictionary를 만든다고 생각

- /movie/{movie_id}/release_dates -> f string 을 떠올리고 반복문 돌리기?  

- query string 이 물음표 뒤의 내용 

- ?기준으로 앞: 요청을 어디로 보낼지 뒤: 요청을 무엇을 담아 보낼지

- base_url , path , parmas 공식처럼 외우기 

- class 쓸 때 핵심: 각단계별로 타입